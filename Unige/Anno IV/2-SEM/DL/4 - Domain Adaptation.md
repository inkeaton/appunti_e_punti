+ When working with a domain, we would like our model to be general
+ Maybe, we could even try to use our model to predict inputs from a analogous domain, with **different statistical distribution** of data
+ This is called a **Domain Shift**, and it reduces the performance of our model
	+ A simple example is the change of illumination in a day: Same type of images, but highly different
	+ A neat application could be the generation of training data for real world applications
+ A first solution would be **transfer learning** with fine-tuning, **but** this would work **only** in a **supervised** scenario
+ Also, we should consider the two **label spaces**, which could be equal or one the subset or another...
+ We could also be forced to work **without target data**....
---
+ In theory, what we want is a model which learns **undiscriminative features** between the two domains
+ Deep methods to learn these can be classified as:
	+ **Discrepancy**-based: fine-tuning the deep network with labeled or unlabeled target data to diminish the domain shift
	+ **Adversarial**-based: using domain discriminators to encourage domain confusion through an adversarial objective
	+ **Reconstruction**-based: using the data reconstruction as an auxiliary task to ensure feature invariance
### Discrepancy-Based
+ To approach this problem, many existing methods aim to bound the target error by the source error plus a **discrepancy metric** between the source and the target, e.g., maximum mean discrepancies (MMD)
+ A first method is the **Domain Adaptation Network**
	+ We train on the source set, and freeze the first few layers, the ones which capture more general features
	+ After that, we process both datasets, and compute the distance between outputs using a specific type of kernel
	+ We fine-tune the latter layers based on the results, adding a section to the objective function which represents MMD
+ This can be improved with **Weighted Domain Adaptation**, in which we aim to solve the different distribution of the classes between the two domains
	+ We use weights for the classes, by taking advantage of **pseudo-labels**, temporary labels generated by a network
+ Another similar approach is **CORAL**, in which we compare **covariances**
### Adversarial-Based
+ Since we want **indiscriminative features**, we could try to train to search for them
+ Adversarial methods work in that direction: we want to promote the emergence of features that are discriminative towards the source classes classification problem, and indiscriminative for a target/source domain classification task.
+ A famous method is **Domain Adversarial Neural Network**
	+ The first component is a regular feed-forward CNN, that predicts source labels
	+ Then, a domain classifier is connected to such network, via a **gradient reversal layer**, ensuring that target and source features are as not distinguishable as possible
		+ Basically we train as a GANs, but we invert the gradient in learning. So instead of getting better at distinguishing, we are getting worse
	+ Both outputs are used to train the feature extractor
+ Another method is **Adversarial Discriminative Domain Adaptation**
	+ *Search more online...*
### Reconstruction-Based
+ Similar idea to **auto-encoders**
+ An approach is **Deep Reconstruction-Classification Network**
	+ + *Search more in slides and online...*
---
+ An important thing to consider is that it is **unrealistic** to assume we **have** the **source** dataset
+ It's **more probable** that we have access to a **model** trained on the original dataset
+ As such, **Source-Free** approaches are the most studied methods in this field
+ This brings us to **Domain Generalization**
	+ + *Search more in slides and online...*